{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\cheminformatics_pipeline\n"
     ]
    }
   ],
   "source": [
    "# import functions\n",
    "import sys,os\n",
    "import glob\n",
    "try: \n",
    "    if(cwd is not None):\n",
    "        from functions.utils_binary import *\n",
    "except:\n",
    "    %cd ..\n",
    "    cwd = os.getcwd()\n",
    "    sys.path.insert(0,cwd)\n",
    "    from functions.utils_binary import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for training\n",
    "defineXY(testSize=0.2, trainSize=0.8, randomState=4) # only needed to be run once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting methods (XGBoost, Ada and LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting search space\n",
    "\n",
    "xgb_search = {\n",
    "'learning_rate': Real(0.01, 1.0, 'uniform'),\n",
    "'max_depth': Integer(2, 12),\n",
    "'subsample': Real(0.1, 1.0, 'uniform'),\n",
    "'colsample_bytree': Real(0.1, 1.0, 'uniform'),\n",
    "'reg_alpha': Real(1e-9, 100., 'uniform'),\n",
    "'n_estimators': Integer(50, 5000)\n",
    "}\n",
    "\n",
    "ada_search = {\n",
    "    'learning_rate': Real(0.005, 0.9, prior=\"log-uniform\"),\n",
    "    'n_estimators': Integer(1, 1000),\n",
    "}\n",
    "\n",
    "lgbm_search = {\n",
    "    'reg_sqrt': Categorical([True, False]),\n",
    "    'learning_rate': Real(0.01, 1.0, 'log-uniform'),     # Boosting learning rate\n",
    "    'n_estimators': Integer(30, 5000),                   # Number of boosted trees to fit\n",
    "    'num_leaves': Integer(2, 512),                       # Maximum tree leaves for base learners\n",
    "    'max_depth': Integer(-1, 256),                       # Maximum tree depth for base learners, <=0 means no limit\n",
    "    'subsample': Real(0.01, 1.0, 'uniform'),             # Subsample ratio of the training instance\n",
    "    'subsample_freq': Integer(1, 10),                    # Frequency of subsample, <=0 means no enable\n",
    "    'colsample_bytree': Real(0.01, 1.0, 'uniform'),      # Subsample ratio of columns when constructing each tree\n",
    "    'reg_lambda': Real(1e-9, 100.0, 'log-uniform'),      # L2 regularization\n",
    "    'reg_alpha': Real(1e-9, 100.0, 'log-uniform'),       # L1 regularization\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scorer\n",
    "f1_scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "# Setting the validation strategy\n",
    "inner_skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "outer_skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate models\n",
    "init_models = [xgb.XGBClassifier(), LGBMClassifier(), AdaBoostClassifier()]\n",
    "\n",
    "# search spaces\n",
    "search_spaces = [xgb_search, lgbm_search, ada_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fp generated\n",
    "fp_generated = ['ecfp_fp_2_1024', 'fcfp_fp_2_1024', 'maccs_fp']\n",
    "\n",
    "for fp in fp_generated:\n",
    "\n",
    "    # run through x train\n",
    "    for file in os.listdir('./data/curated_data/x/binary/x_train/'):\n",
    "\n",
    "        # run through y train\n",
    "        for file_ in os.listdir('./data/curated_data/y/binary/y_train/'):\n",
    "\n",
    "            # check if file is json file\n",
    "            if file.endswith('json'):\n",
    "\n",
    "                #check if files share the same fp, if so, continue\n",
    "                if file.find(fp) != -1 and  file_.find(fp) != -1:\n",
    "                    \n",
    "                    # load x_train\n",
    "                    with open(f'./data/curated_data/x/binary/x_train/{file}', 'r') as x_train:\n",
    "                        x_train = json.load(x_train)\n",
    "                        x_train= np.asarray(x_train)\n",
    "\n",
    "\n",
    "                    # load y_train\n",
    "                    with open(f'./data/curated_data/y/binary/y_train/{file_}', 'r') as y_train:\n",
    "                        y_train = json.load(y_train)\n",
    "                        y_train= np.asarray(y_train)\n",
    "\n",
    "                    # training\n",
    "                    bayessearch(\n",
    "                        models = init_models, \n",
    "                        search_spaces = search_spaces, \n",
    "                        scorer = f1_scorer,\n",
    "                        inner_cv = inner_skf,\n",
    "                        outer_cv = outer_skf,\n",
    "                        x = x_train,\n",
    "                        y = y_train,\n",
    "                        fp = fp\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "validatemodels() #only for boosting methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non boosting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make sure when introducing a new classifier to create a folder with the model name at the following directories:\n",
    "./data/models/binary/metrics/BACC/{MODEL_NAME}\n",
    "./data/models/binary/metrics/AUC/{MODEL_NAME}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# define search space\n",
    "rf_search = {\n",
    "    'max_features': ['sqrt'],\n",
    "    'n_estimators': [100, 1000],\n",
    "    'max_depth': [2, 100],\n",
    "    'min_samples_leaf': [1,20], \n",
    "    'min_samples_split': [2, 20]\n",
    "    }\n",
    "\n",
    "svc_search = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']}\n",
    "\n",
    "knn_search = {\n",
    "    'n_neighbors' : [3, 5, 11, 19],\n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'metric' : ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# define variables\n",
    "fp = 'ecfp_fp_2_1024'\n",
    "model = RandomForestClassifier # classifier \n",
    "#model = SVC\n",
    "#model = KNeighborsClassifier\n",
    "model_name = 'rf' \n",
    "\n",
    "\n",
    "# load x_train\n",
    "with open(f'./data/curated_data/x/binary/x_train/x_train_{fp}.json', 'r') as x_train:\n",
    "    x_train = json.load(x_train)\n",
    "    x_train= np.asarray(x_train)\n",
    "\n",
    "\n",
    "# load y_train\n",
    "with open(f'./data/curated_data/y/binary/y_train/y_train_{fp}.json', 'r') as y_train:\n",
    "    y_train = json.load(y_train)\n",
    "    y_train= np.asarray(y_train)\n",
    "\n",
    "# scorer\n",
    "f1_scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "# Setting the validation strategy\n",
    "inner_skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "outer_skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "# callback funtions\n",
    "overdone_control = DeltaYStopper(delta=0.0001) # early stop\n",
    "time_limit_control = DeadlineStopper(total_time=60*60*4) #7h time limit\n",
    "\n",
    "# initialize model\n",
    "model_ini = model(random_state=0) # classifier \n",
    "\n",
    "# invoke bayes search\n",
    "opt = BayesSearchCV(\n",
    "    estimator=model_ini, \n",
    "    search_spaces=rf_search,\n",
    "    scoring=f1_scorer,\n",
    "    cv=inner_skf,\n",
    "    n_points=1,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=False,\n",
    "    refit=False,\n",
    "    optimizer_kwargs={'base_estimator': 'GP'},\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# search for best params\n",
    "best_params = report_perf(opt, x_train, y_train, callbacks=[overdone_control, time_limit_control])\n",
    "\n",
    "# Transferring best parameters to basic classifier\n",
    "basic_clas = model(**best_params)\n",
    "\n",
    "# cross validate with best params\n",
    "\n",
    "# cross validate to get confusion matrix\n",
    "cv_results = cross_validate(basic_clas, x_train, y_train, cv=outer_skf, scoring=confusion_matrix_scorer)\n",
    "# cross validate to get auc\n",
    "cv_auc = cross_validate(basic_clas, x_train, y_train, cv=outer_skf, scoring='roc_auc')\n",
    "\n",
    "# save cross validation auc metrics\n",
    "cv_auc = pd.DataFrame(cv_auc)\n",
    "cv_auc.to_csv(f'./data/models/binary/metrics/AUC/{model_name}/{model_name}_classifier_auc_{fp}.csv', index = False)\n",
    "\n",
    "# save cross validation confusion matrix\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results.to_csv(f'./data/models/binary/metrics/{model_name}_classifier_5cv_{fp}.csv', index = False)\n",
    "cv_results.to_csv(f'./data/models/binary/metrics/BACC/{model_name}/{model_name}_classifier_5cv_{fp}.csv', index = False)\n",
    "\n",
    "# fit model with entire dataset\n",
    "model = basic_clas.fit(x_train, y_train)\n",
    "\n",
    "# save model\n",
    "dump(model, f'./data/models/binary/{model_name}_classifier_{fp}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 FOLD CROSS VALIDATION PLOT WITH STD \n",
    "\n",
    "model_metrics = pd.read_csv(f'./data/models/binary/metrics/rf_classifier_5cv_ecfp_fp_2_1024.csv')\n",
    "metrics_inner = metrics_internal_binary(model_metrics)\n",
    "\n",
    "\n",
    "mean_metrics = [np.mean(metrics_inner[column]) for column in metrics_inner.columns]\n",
    "std_metrics = [np.std(metrics_inner[column]) for column in metrics_inner.columns]\n",
    "labels = ['Se', 'Sp', 'Precision', 'BACC', 'MCC', 'F1']\n",
    "\n",
    "x_pos = np.arange(len(labels))\n",
    "fig, ax = plt.subplots()\n",
    "barplot = ax.bar(x_pos, mean_metrics,\n",
    "    yerr=std_metrics,\n",
    "    align='center',\n",
    "    alpha=0.5,\n",
    "    ecolor='black',\n",
    "    capsize=10, color = 'gray')\n",
    "ax.set_ylabel('Value')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.yaxis.grid(False)\n",
    "\n",
    "ax.bar_label(barplot, labels=['±%.2f' % e for e in std_metrics], padding=3, color='black', fontsize=9)\n",
    "\n",
    "# Save the figure and show\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'./data/figs/rf_classifier_5cv_ecfp_fp_2_1024_5cv.png', dpi=300)\n",
    "#plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT AUC COMPARISON PLOT PER FINGERPRINT \n",
    "\n",
    "# make sure to enter the correct directory where auc metrics are saved\n",
    "model_0 = pd.read_csv(f'./data/models/binary/metrics/AUC/rf/rf_classifier_auc_ecfp_fp_2_1024.csv')\n",
    "model_1 = pd.read_csv(f'./data/models/binary/metrics/AUC/lgbm/lgbm_classifier_auc_ecfp_fp_2_1024.csv')\n",
    "model_2 = pd.read_csv(f'./data/models/binary/metrics/AUC/xgb/xgb_classifier_auc_ecfp_fp_2_1024.csv')\n",
    "\n",
    "\n",
    "# change the names of the algorithm accordingly (if needed you can increase the number of models compared)\n",
    "dictHolder = pd.DataFrame({'x_values':[], 'LGBM': [], 'ADABoost': [], 'XGBoost':[]})\n",
    "\n",
    "# make sure to add one more dictHolder if more than 3 algorithms are added, or to remove one if needed\n",
    "dictHolder['RF'] = [i for i in model_0['test_score']]\n",
    "dictHolder['LGBM'] = [i for i in model_1['test_score']]\n",
    "dictHolder['XGBoost'] = [i for i in model_2['test_score']]\n",
    "dictHolder['x_values'] = [f'fold_{i}' for i in range(5)]\n",
    "\n",
    "# multiple line plots, add one for each model and change algorithm name accordingly\n",
    "plt.plot( 'x_values', 'LGBM', data=dictHolder, marker='^', markerfacecolor='white', markersize=8, color='blue', linewidth=2, \n",
    "linestyle='dashed', label = f\"LGBM mean {round(st.mean(dictHolder['LGBM']), 2)}\")\n",
    "\n",
    "plt.plot( 'x_values', 'XGBoost', data=dictHolder, marker='v', markerfacecolor='white', markersize=8, color='red', linewidth=2, \n",
    "linestyle='dashed', label = f\"XGBoost mean {round(st.mean(dictHolder['XGBoost']), 2)}\")\n",
    "\n",
    "plt.plot( 'x_values', 'RF', data=dictHolder, marker='x', markerfacecolor='white', markersize=8, color='black', linewidth=2, \n",
    "linestyle='dashed', label = f\"RF mean {round(st.mean(dictHolder['RF']), 2)}\")\n",
    "\n",
    "\n",
    "# choose a title\n",
    "plt.title(f'5-fold cross validation ECFP4 1024')\n",
    "\n",
    "# choose label for y\n",
    "plt.ylabel('AUC')\n",
    "\n",
    "# show legend\n",
    "plt.legend()\n",
    "\n",
    "# save, remmeber to add the correct fingerprint in the image name before saving\n",
    "#plt.savefig(f'./data/figs/auc_compared_nonboost_ecfp_fp_2_1024.png', dpi=300)\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT BACC COMPARISON PLOT PER FINGERPRINT \n",
    "\n",
    "# make sure to enter the correct directory where auc metrics are saved\n",
    "model_0 = pd.read_csv(f'./data/models/binary/metrics/BACC/rf/rf_classifier_5cv_ecfp_fp_2_1024.csv')\n",
    "model_1 = pd.read_csv(f'./data/models/binary/metrics/BACC/lgbm/lgbm_classifier_5cv_ecfp_fp_2_1024.csv')\n",
    "model_2 = pd.read_csv(f'./data/models/binary/metrics/BACC/xgb/xgb_classifier_5cv_ecfp_fp_2_1024.csv')\n",
    "\n",
    "\n",
    "model_0 = metrics_internal_binary(model_0)\n",
    "model_1 = metrics_internal_binary(model_1)\n",
    "model_2 = metrics_internal_binary(model_2)\n",
    "\n",
    "# change the names of the algorithm accordingly (if needed you can increase the number of models compared)\n",
    "dictHolder = pd.DataFrame({'x_values':[], 'LGBM': [], 'ADABoost': [], 'XGBoost':[]})\n",
    "\n",
    "# make sure to add one more dictHolder if more than 3 algorithms are added, or to remove one if needed\n",
    "dictHolder['RF'] = [i for i in model_0['BACC']]\n",
    "dictHolder['LGBM'] = [i for i in model_1['BACC']]\n",
    "dictHolder['XGBoost'] = [i for i in model_2['BACC']]\n",
    "dictHolder['x_values'] = [f'fold_{i}' for i in range(5)]\n",
    "\n",
    "# multiple line plots, add one for each model and change algorithm name accordingly\n",
    "plt.plot( 'x_values', 'LGBM', data=dictHolder, marker='^', markerfacecolor='white', markersize=8, color='blue', linewidth=2, \n",
    "linestyle='dashed', label = f\"LGBM mean {round(st.mean(dictHolder['LGBM']), 2)}\")\n",
    "\n",
    "plt.plot( 'x_values', 'XGBoost', data=dictHolder, marker='v', markerfacecolor='white', markersize=8, color='red', linewidth=2, \n",
    "linestyle='dashed', label = f\"XGBoost mean {round(st.mean(dictHolder['XGBoost']), 2)}\")\n",
    "\n",
    "plt.plot( 'x_values', 'RF', data=dictHolder, marker='x', markerfacecolor='white', markersize=8, color='black', linewidth=2, \n",
    "linestyle='dashed', label = f\"RF mean {round(st.mean(dictHolder['RF']), 2)}\")\n",
    "\n",
    "\n",
    "# choose a title\n",
    "plt.title(f'5-fold cross validation ECFP4 1024')\n",
    "\n",
    "# choose label for y\n",
    "plt.ylabel('BACC')\n",
    "\n",
    "# show legend\n",
    "plt.legend()\n",
    "\n",
    "# save, remmeber to add the correct fingerprint in the image name before saving\n",
    "#plt.savefig(f'./data/figs/bacc_compared_nonboost_ecfp_fp_2_1024.png', dpi=300)\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTERNAL VALIDATION\n",
    "\n",
    "# import model\n",
    "model = load('./data/models/binary/rf_classifier_ecfp_fp_2_1024.joblib')\n",
    "\n",
    "# load x external and y external (make sure to load y_ext and x_ext with the same fp used as the model)\n",
    "with open(f'./data/curated_data/y/binary/y_ext/y_ext_ecfp_fp_2_1024.json', 'r') as y_ext:\n",
    "    y_ext = json.load(y_ext)\n",
    "    y_ext = np.asarray(y_ext)\n",
    "\n",
    "# load x_ext\n",
    "with open(f'./data/curated_data/x/binary/x_ext/x_ext_ecfp_fp_2_1024.json', 'r') as x_ext:\n",
    "    x_ext = json.load(x_ext)\n",
    "    x_ext = np.asarray(x_ext)\n",
    "\n",
    "# load auc metric\n",
    "aucmetric_inner = pd.read_csv(f'./data/models/binary/metrics/AUC/rf/rf_classifier_auc_ecfp_fp_2_1024.csv')\n",
    "\n",
    "# load 5cv metrics\n",
    "crossMetrics = pd.read_csv(f'./data/models/binary/metrics/rf_classifier_5cv_ecfp_fp_2_1024.csv')\n",
    "\n",
    "# calculate external metrics\n",
    "metrics_ext, cm = metrics_binary(model, x_ext, y_ext)\n",
    "\n",
    "# plot side by side comparison\n",
    "\n",
    "\n",
    "metrics_inner = metrics_internal_binary(crossMetrics)\n",
    "\n",
    "metrics__innermean = [np.mean(metrics_inner[column]) for column in metrics_inner.columns]\n",
    "aucmetric_inner_mean = np.mean(aucmetric_inner['test_score'])\n",
    "metrics__innermean.append(aucmetric_inner_mean)\n",
    "\n",
    "# error\n",
    "error = [np.std(metrics_inner[column]) for column in metrics_inner.columns]\n",
    "error.append(np.std(aucmetric_inner['test_score']))\n",
    "error\n",
    "\n",
    "#round numbers\n",
    "metrics__innermean = [round(number, 2) for number in metrics__innermean]\n",
    "metrics_ext = [round(number, 2) for number in metrics_ext['value']]\n",
    "                            \n",
    "\n",
    "# Example data\n",
    "metrics = ['Se','Sp','Precision', 'BACC', 'MCC', 'F1', 'AUC']\n",
    "\n",
    "y_pos = np.arange(len(metrics))\n",
    "width = 0.4\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "inner_bar = ax.barh(y_pos + width, metrics__innermean, width, color='lightgray', xerr=error, ecolor='black', capsize=2, label='Internal Set')\n",
    "ext_bar = ax.barh(y_pos, metrics_ext, width, color='dimgray', label='External Set')\n",
    "\n",
    "ax.bar_label(inner_bar, padding=2, label_type='edge')\n",
    "ax.bar_label(ext_bar, padding=2, label_type='edge')\n",
    "\n",
    "ax.set(yticks=y_pos + width, yticklabels=metrics, ylim=[2*width - 1, len(metrics)])\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=False, ncol=5)\n",
    "\n",
    "fig.set_size_inches(5, 5)\n",
    "fig.tight_layout()\n",
    "max_list = [max(metrics__innermean), max(metrics_ext)]\n",
    "plt.xlim([0, max(max_list)+0.1])\n",
    "#plt.savefig(f'./data/figs/comparison_metrics_rf_classifier_ecfp_fp_2_1024.png', dpi=300)\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "\n",
    "# save fig\n",
    "plt.title(f'Confusion Matrix RF ECFP4 1024')\n",
    "#plt.savefig(f'./data/figs/confusion_matrix_rf_ecfp_2_1024.png', dpi=300)\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [cm[1, 1], cm[0, 0]]\n",
    "B = [cm[1, 0], cm[0, 1]]\n",
    "\n",
    "fig = plt.figure(facecolor=\"white\")\n",
    "\n",
    "ax = fig.subplots()\n",
    "bar_width = 0.9\n",
    "bar_l = np.arange(1, 3)\n",
    "tick_pos = [i + (bar_width / 30) for i in bar_l]\n",
    "\n",
    "ax2 = ax.bar(bar_l, A, width=bar_width, label=\"A\", color=\"darkseagreen\")\n",
    "ax1 = ax.bar(bar_l, B, bottom=A, width=bar_width, label=\"B\", color=\"lightcoral\")\n",
    "ax.set_ylabel(\"Count\", fontsize=10)\n",
    "totals = [sum([cm[1, 1], cm[1, 0]]), sum([cm[0, 0], cm[0, 1]])]\n",
    "plt.legend([\"Predicted correctly\", \"Predicted wrongly\"], bbox_to_anchor=(0.45, -0.09), loc='upper center', ncol=1)\n",
    "plt.xticks(tick_pos, [f\"Total Negatives: {totals[0]}\", f\"Total Positives: {totals[1]}\"], fontsize=10)\n",
    "plt.title(f'Confusion Matrix RF ECFP4 1024')\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "for r1, r2 in zip(ax2, ax1):\n",
    "    h1 = r1.get_height()\n",
    "    h2 = r2.get_height()\n",
    "    plt.text(r1.get_x() + r1.get_width() / 2., h1 / 2., \"%d\" % h1, ha=\"center\", va=\"bottom\", color=\"white\", fontsize=10, fontweight=\"bold\")\n",
    "    plt.text(r2.get_x() + r2.get_width() / 2., h1 + h2 / 2., \"%d\" % h2, ha=\"center\", va=\"bottom\", color=\"white\", fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "#plt.savefig(f'./data/figs/barplotconfusion_matrix_{modelname}_{fp_used}.png', dpi=300, bbox_inches = 'tight')\n",
    "#plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('chem_pipeline')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a59e22669eba1dc6e4d930302cbb600e9d71d81892f6be3c25d1b723809ef057"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
